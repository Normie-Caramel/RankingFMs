{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from models.models import *\n",
    "from utils.utils import *\n",
    "from utils.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 1\n",
    "RANDOM_SEED = 42\n",
    "WEIGHT_DECAY = 1e-6\n",
    "MODEL_PATH = 'best/fm_full_tra.pth'\n",
    "LOG_PATH = 'log/fm_full_tra.csv'\n",
    "DATA_PATH = 'data/'\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events, users, items = load_data(DATA_PATH)\n",
    "train_df, valid_df = train_test_split(events, test_size=0.2, random_state=RANDOM_SEED)\n",
    "train_mat = get_csr_mat(train_df, users.shape[0], items.shape[0])\n",
    "valid_mat = get_csr_mat(events, users.shape[0], items.shape[0])\n",
    "train_data = BPRData(train_df, train_mat, users, items, num_neg=1, device=device, add_weight=True)\n",
    "valid_data = BPRData(valid_df, valid_mat, users, items, num_neg=1, device=device, add_weight=True)\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_dims, dense_dim = train_data.get_dims()\n",
    "model = FM(sparse_dims, dense_dim, embed_dim=32).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(LOG_PATH, 'w') as f:\n",
    "    f.write('train_loss,valid_loss,train_precision,valid_precision,roc_auc_train,roc_auc_valid\\n')\n",
    "p_best = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_data.neg_sample()\n",
    "    progress = tqdm(train_loader, desc=f'Epoch {epoch + 1}', disable=False)\n",
    "    for x_pos_sparse, x_pos_dense, x_neg_sparse, x_neg_dense, weight in progress:\n",
    "        optimizer.zero_grad()\n",
    "        pos_score = model(x_pos_sparse, x_pos_dense)\n",
    "        neg_score = model(x_neg_sparse, x_neg_dense)\n",
    "        loss = -(torch.log(torch.sigmoid(pos_score - neg_score)) * weight).mean()\n",
    "        if torch.isinf(loss): continue\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    valid_data.neg_sample()\n",
    "    for x_pos_sparse, x_pos_dense, x_neg_sparse, x_neg_dense, weight in valid_loader:\n",
    "        pos_score = model(x_pos_sparse, x_pos_dense)\n",
    "        neg_score = model(x_neg_sparse, x_neg_dense)\n",
    "        loss = -(torch.log(torch.sigmoid(pos_score - neg_score)) * weight).mean()\n",
    "        valid_loss += loss.item()\n",
    "    valid_loss /= len(valid_loader)\n",
    "\n",
    "    p_train, p_valid, roc_train, roc_valid = \\\n",
    "        metrics_at_k(model, valid_df, train_df, users, items, k=10, device=device, precision=True, roc_auc=True)\n",
    "    if p_valid > p_best:\n",
    "        p_best = p_valid\n",
    "        torch.save(model.state_dict(), MODEL_PATH)\n",
    "    with open(LOG_PATH, 'a') as f:\n",
    "        f.write(f'{train_loss:.4f},{valid_loss:.4f},{p_train:.4f},{p_valid:.4f},{roc_train:.4f},{roc_valid:.4f}\\n')\n",
    "        \n",
    "    print(f'Train Loss: {train_loss:.4f}, ' +\n",
    "          f'Valid Loss: {valid_loss:.4f}, ' +\n",
    "          f'Precision@10 (Train): {p_train:.4f}, ' +\n",
    "          f'Precision@10 (Valid): {p_valid:.4f}, ' +\n",
    "          f'ROC AUC (Train): {roc_train:.4f},' +\n",
    "          f'ROC AUC (Valid): {roc_valid:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wk6_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
